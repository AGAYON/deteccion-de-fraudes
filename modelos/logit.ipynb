{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cambiar directorio a 'outputs' para leer los CSV\n",
    "os.chdir(\"C:/repo personal/PYTHON/deteccion de fraudes/outputs\")\n",
    "\n",
    "# Subir un nivel desde 'modelos/' a la raíz 'deteccion de fraudes/'\n",
    "sys.path.append(r\"C:/repo personal/PYTHON/deteccion de fraudes/scripts\")\n",
    "# Importar la función ajustar_umbral desde utils.py\n",
    "from utils import ajustar_umbral\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar datos\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").squeeze()\n",
    "y_test = pd.read_csv(\"y_test.csv\").squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE para balancear los datos de entrenamiento\n",
    "\n",
    "smote = SMOTE(random_state=42)  # Crear una instancia de SMOTE\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Datos balanceados con SMOTE:\")\n",
    "print(f\"Tamaño original: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Tamaño balanceado: {X_train_balanced.shape}, {y_train_balanced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo base\n",
    "model = LogisticRegression(max_iter=5000, random_state=42)\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en el set de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# También obtenemos probabilidades\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir umbrales\n",
    "thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "# Calcular métricas para cada umbral\n",
    "resultados = ajustar_umbral(y_test, y_prob, thresholds)\n",
    "\n",
    "# Convertir resultados a un DataFrame para visualización\n",
    "resultados_df = pd.DataFrame(resultados, columns=[\"Threshold\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "# Mostrar resultados\n",
    "print(resultados_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar métricas en función del umbral\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(resultados_df[\"Threshold\"], resultados_df[\"Precision\"], label=\"Precision\", marker=\"o\")\n",
    "plt.plot(resultados_df[\"Threshold\"], resultados_df[\"Recall\"], label=\"Recall\", marker=\"o\")\n",
    "plt.plot(resultados_df[\"Threshold\"], resultados_df[\"F1-Score\"], label=\"F1-Score\", marker=\"o\")\n",
    "plt.title(\"Métricas en función del umbral\")\n",
    "plt.xlabel(\"Umbral\")\n",
    "plt.ylabel(\"Valor de la métrica\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el mejor umbral basado en F1-Score\n",
    "mejor_umbral = resultados_df.loc[resultados_df[\"F1-Score\"].idxmax(), \"Threshold\"]\n",
    "print(f\"Mejor umbral basado en F1-Score: {mejor_umbral:.2f}\")\n",
    "\n",
    "# Generar predicciones finales con el mejor umbral\n",
    "y_pred_final = (y_prob >= mejor_umbral).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión con el mejor umbral\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_final)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Clase 0\", \"Clase 1\"], yticklabels=[\"Clase 0\", \"Clase 1\"])\n",
    "plt.title(f\"Matriz de Confusión (Umbral = {mejor_umbral:.2f})\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte de clasificación con el mejor umbral\n",
    "print(\"Reporte de Clasificación con el mejor umbral:\")\n",
    "print(classification_report(y_test, y_pred_final, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular Precision-Recall AUC\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "pr_auc = auc(recall, precision)\n",
    "# Imprimir métricas clave\n",
    "print(f\"PR-AUC: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar curva Precision-Recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f\"PR-AUC = {pr_auc:.4f}\")\n",
    "plt.title(\"Curva Precision-Recall\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
