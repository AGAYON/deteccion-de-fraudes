{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Cambiar directorio a 'outputs' para leer los CSV\n",
    "os.chdir(\"C:/repo personal/PYTHON/deteccion de fraudes/outputs\")\n",
    "\n",
    "# Subir un nivel desde 'modelos/' a la raíz 'deteccion de fraudes/'\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Importar la función ajustar_umbral desde utils.py\n",
    "from scripts.utils import ajustar_umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").squeeze()\n",
    "y_test = pd.read_csv(\"y_test.csv\").squeeze()\n",
    "\n",
    "print(f\"Tamaño de X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Tamaño de X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE para balancear los datos de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Datos balanceados con SMOTE:\")\n",
    "print(f\"Tamaño original: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Tamaño balanceado: {X_train_balanced.shape}, {y_train_balanced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la proporción de clases para penalizaciones de error por fraude\n",
    "ratio_neg_pos = np.sum(y_train_balanced == 0) / np.sum(y_train_balanced == 1)\n",
    "\n",
    "# Definir el modelo base\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='aucpr',\n",
    "    scale_pos_weight=ratio_neg_pos,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_dist = {\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='average_precision',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ajustar el modelo\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el objeto completo\n",
    "joblib.dump(random_search, '../outputs/random_search_xgb.pkl')\n",
    "\n",
    "# Para usar después y no correr el modelo completo de nuevo:\n",
    "random_search = joblib.load('../outputs/random_search_xgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo con los mejores hiperparámetros\n",
    "best_xgb = random_search.best_estimator_\n",
    "best_xgb.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "y_prob = best_xgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el umbral de predicción\n",
    "thresholds = np.arange(0.4, 0.9, 0.02)\n",
    "resultados = ajustar_umbral(y_test, y_prob, thresholds)\n",
    "\n",
    "# Convertir resultados a un DataFrame para visualización\n",
    "resultados_df = pd.DataFrame(resultados, columns=[\"Threshold\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "# Mostrar resultados\n",
    "print(resultados_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar métricas en función del umbral\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(resultados_df[\"Threshold\"], resultados_df[\"Precision\"], label=\"Precision\", marker=\"o\")\n",
    "plt.plot(resultados_df[\"Threshold\"], resultados_df[\"Recall\"], label=\"Recall\", marker=\"o\")\n",
    "plt.plot(resultados_df[\"Threshold\"], resultados_df[\"F1-Score\"], label=\"F1-Score\", marker=\"o\")\n",
    "plt.title(\"Métricas en función del umbral\")\n",
    "plt.xlabel(\"Umbral\")\n",
    "plt.ylabel(\"Valor de la métrica\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Seleccionar el mejor umbral basado en F1-Score\n",
    "mejor_umbral = resultados_df.loc[resultados_df[\"F1-Score\"].idxmax(), \"Threshold\"]\n",
    "print(f\"Mejor umbral basado en F1-Score: {mejor_umbral:.2f}\")\n",
    "\n",
    "# Generar predicciones finales con el mejor umbral\n",
    "y_pred_final = (y_prob >= mejor_umbral).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión con el mejor umbral\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_final)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Clase 0\", \"Clase 1\"], yticklabels=[\"Clase 0\", \"Clase 1\"])\n",
    "plt.title(f\"Matriz de Confusión (Umbral = {mejor_umbral:.2f})\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte de clasificación con el mejor umbral\n",
    "print(\"Reporte de Clasificación con el mejor umbral:\")\n",
    "print(classification_report(y_test, y_pred_final, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular Precision-Recall AUC\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "# Visualizar curva Precision-Recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f\"PR-AUC = {pr_auc:.4f}\", color=\"blue\")\n",
    "plt.title(\"Curva Precision-Recall\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Externa para validar robustez\n",
    "\n",
    "# Evaluar usando 5-fold Cross Validation en el set de entrenamiento\n",
    "cv_scores = cross_val_score(\n",
    "    best_xgb, X_train_balanced, y_train_balanced,\n",
    "    scoring='average_precision',  # PR-AUC promedio\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"PR-AUC promedio por Cross-Validation:\", cv_scores.mean())\n",
    "print(\"PR-AUC de cada fold:\", cv_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
